ollama:
  server_port: 11434
  sched_spread: true
  flash_attention: true
  max_retries: 5
  retry_delay: 60
  # You can use any model available in your Ollama installation
  # Recommended models:
  # - qwen2.5-coder:7b (default)
  # - codellama:7b
  # - deepseek-coder:6.7b
  # - phind-codellama:34b
  # Check available models with: ollama list
  model: "qwen2.5-coder:7b"
  temperature: 0.7
  top_p: 0.95
  context_window: 4096
  timeout: 120  # Timeout in seconds
  keep_alive: true  # Keep model loaded

paths:
  auxiliary_file: "class_relationships.json"
  log_file: "logs/java_doc_ai.log"

logging:
  level: "DEBUG"
  rotation: "1 day"
  retention: "1 week"
  format: "%(asctime)s - %(levelname)s - %(message)s"

language:
  default: "en"

processing:
  batch_size: 10
  max_concurrent_tasks: 4
  timeout: 300
